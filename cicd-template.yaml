apiVersion: v1
kind: Template
labels:
  group: cicd
message: |-
  Use the following credentials for login:
      Jenkins: use your OpenShift credentials
      Nexus: admin/admin123
      SonarQube: admin/admin
      Gogs Git Server: gogs/gogs"
metadata:
  annotations:
    iconClass: icon-jenkins
    tags: instant-app,jenkins,gogs,nexus,sonarqube,clair,cicd
  name: cicd
objects:
- apiVersion: v1
  groupNames: null
  kind: RoleBinding
  metadata:
    name: default_admin
  roleRef:
    name: admin
  subjects:
  - kind: ServiceAccount
    name: default
# Jenkins
- apiVersion: v1
  kind: ImageStream
  metadata:
    name: jenkins
  spec:
    tags:
    - from:
        kind: DockerImage
        name: ${JENKINS_IMAGE_SOURCE}:${JENKINS_IMAGE_TAG}
      importPolicy:
        scheduled: true
      name: ${JENKINS_IMAGE_TAG}
      referencePolicy:
        type: Local
- apiVersion: v1
  data:
    proxy.xml: |-
      <?xml version='1.0' encoding='UTF-8'?>
      <proxy>
        <name>${PROXY_HOST}</name>
        <port>${PROXY_PORT}</port>
        <noProxyHost>*.svc.cluster.local
      gogs
      sonarqube
      clair
      nexus
      kubernetes.default
      kubernetes.default.svc
      *.local</noProxyHost>
        <secretPassword></secretPassword>
        <testUrl>https://github.com</testUrl>
      </proxy>
  kind: ConfigMap
  metadata:
    name: jenkins-conf
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    name: jenkins-data
  spec:
    accessModes: [ ReadWriteOnce ]
    resources:
      requests:
        storage: ${JENKINS_VOLUME_CAPACITY}
- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    name: jenkins
  spec:
    replicas: 1
    selector:
      name: jenkins
    strategy:
      recreateParams:
        timeoutSeconds: 900
      type: Recreate
    template:
      metadata:
        labels:
          name: jenkins
      spec:
        containers:
        - env:
          - name: OPENSHIFT_ENABLE_OAUTH
            value: "true"
          - name: OPENSHIFT_ENABLE_REDIRECT_PROMPT
            value: "true"
          - name: DISABLE_ADMINISTRATIVE_MONITORS
            value: "false"
          - name: INSTALL_PLUGINS
            value: ${JENKINS_PLUGINS}
          - name: KUBERNETES_MASTER
            value: https://kubernetes.default:443
          - name: KUBERNETES_TRUST_CERTIFICATES
            value: "true"
          - name: JENKINS_SERVICE_NAME
            value: jenkins
          - name: JNLP_SERVICE_NAME
            value: jenkins-jnlp
          - name: JAVA_GC_OPTS
            value: -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+ParallelRefProcEnabled -XX:+ExplicitGCInvokesConcurrent -XX:+UnlockDiagnosticVMOptions -XX:G1SummarizeRSetStatsPeriod=1 -XX:MaxMetaspaceExpansion=64M -XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=20
          image: ' '
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 20
            httpGet:
              path: /login
              port: 8080
            initialDelaySeconds: 120
            periodSeconds: 30
            timeoutSeconds: 10
          name: jenkins
          readinessProbe:
            httpGet:
              path: /login
              port: 8080
            initialDelaySeconds: 20
            periodSeconds: 20
            timeoutSeconds: 10
          resources:
            limits:
              cpu: "1"
              memory: 3Gi
            requests:
              cpu: 200m
              memory: 1Gi
          volumeMounts:
          - mountPath: /var/lib/jenkins
            name: data
          - mountPath: /var/lib/jenkins/caches
            name: cache
          - mountPath: /var/lib/jenkins/proxy.xml
            name: conf
            subPath: proxy.xml
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        serviceAccountName: jenkins
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: jenkins-data
        - emptyDir: {}
          name: cache
        - configMap:
            defaultMode: 420
            name: jenkins-conf
          name: conf
    triggers:
    - type: ConfigChange
    - imageChangeParams:
        automatic: true
        containerNames:
        - jenkins
        from:
          kind: ImageStreamTag
          name: jenkins:${JENKINS_IMAGE_TAG}
      type: ImageChange
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      serviceaccounts.openshift.io/oauth-redirectreference.jenkins: '{"kind":"OAuthRedirectReference","apiVersion":"v1","reference":{"kind":"Route","name":"jenkins"}}'
    name: jenkins
- apiVersion: v1
  groupNames: null
  kind: RoleBinding
  metadata:
    name: jenkins_edit
  roleRef:
    name: edit
  subjects:
  - kind: ServiceAccount
    name: jenkins
- apiVersion: v1
  kind: Service
  metadata:
    name: jenkins-jnlp
  spec:
    ports:
    - name: agent
      nodePort: 0
      port: 50000
      protocol: TCP
      targetPort: 50000
    selector:
      name: jenkins
    sessionAffinity: None
    type: ClusterIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/dependencies: '[{"name": "jenkins-jnlp", "namespace": "", "kind": "Service"}]'
      service.openshift.io/infrastructure: "true"
    name: jenkins
  spec:
    ports:
    - name: web
      nodePort: 0
      port: 80
      protocol: TCP
      targetPort: 8080
    selector:
      name: jenkins
    sessionAffinity: None
    type: ClusterIP
- apiVersion: v1
  kind: Route
  metadata:
    annotations:
      haproxy.router.openshift.io/timeout: 4m
      template.openshift.io/expose-uri: http://{.spec.host}{.spec.path}
    name: jenkins
  spec:
    tls:
      insecureEdgeTerminationPolicy: Redirect
      termination: edge
    to:
      kind: Service
      name: jenkins
# Pipeline
- apiVersion: v1
  kind: BuildConfig
  metadata:
    annotations:
      pipeline.alpha.openshift.io/uses: '[{"name": "jenkins", "namespace": "", "kind": "DeploymentConfig"}]'
    labels:
      app: cicd-pipeline
      name: cicd-pipeline
    name: tasks-pipeline
  spec:
    triggers:
      - type: GitHub
        github:
          secret: ${WEBHOOK_SECRET}
      - type: Generic
        generic:
          secret: ${WEBHOOK_SECRET}
    runPolicy: Serial
    source:
      type: None
    strategy:
      jenkinsPipelineStrategy:
        env:
        - name: DEV_PROJECT
          value: ${DEV_PROJECT}
        - name: STAGE_PROJECT
          value: ${STAGE_PROJECT}
        - name: ENABLE_QUAY
          value: "${ENABLE_QUAY}"
        - name: SCAN_IMAGES
          value: "${DEPLOY_CLAIR}"
        jenkinsfile: |-
          def mvnCmd = "mvn -s configuration/cicd-settings-nexus3.xml"
          def cicdProject = ""
          pipeline {
            agent {
              label 'maven'
            }
            stages {
              stage('Build App') {
                steps {
                  git branch: 'eap-7', url: 'http://gogs:3000/gogs/openshift-tasks.git'
                  sh "${mvnCmd} install -DskipTests=true"
                }
              }
              stage('Test') {
                steps {
                  sh "${mvnCmd} test"
                  step([$class: 'JUnitResultArchiver', testResults: '**/target/surefire-reports/TEST-*.xml'])
                }
              }
              stage('Code Analysis') {
                steps {
                  script {
                    sh "${mvnCmd} sonar:sonar -Dsonar.host.url=http://sonarqube:9000 -DskipTests=true"
                  }
                }
              }
              stage('Archive App') {
                steps {
                  sh "${mvnCmd} deploy -DskipTests=true -P nexus3"
                }
              }
              stage('Build Image') {
                steps {
                  sh "cp target/openshift-tasks.war target/ROOT.war"
                  script {
                    openshift.withCluster() {
                      openshift.withProject() {
                        cicdProject = "${openshift.project()}"
                      }
                      openshift.withProject(env.DEV_PROJECT) {
                        openshift.selector("bc", "tasks").startBuild("--from-file=target/ROOT.war", "--wait=true")
                      }
                    }
                  }
                }
              }
              stage('Scan Image') {
                when {
                  expression {
                    return env.SCAN_IMAGES == "true"
                  }
                }
                agent {
                  kubernetes {
                    cloud 'openshift'
                    label 'klar'
                    containerTemplate {
                      name 'jnlp'
                      image "docker-registry.default.svc:5000/${cicdProject}/jenkins-agent-klar:master"
                    }
                    inheritFrom 'maven'
                    serviceAccount 'jenkins'
                  }
                }
                steps {
                  script {
                    openshift.withCluster() {
                      try {
                        sh """
                        export HTTP_PROXY= HTTPS_PROXY= NO_PROXY=
                        export http_proxy= https_proxy= no_proxy=
                        echo "==== Scanning task:latest ===="
                        if ! CLAIR_ADDR="http://clair:6060" \\
                            CLAIR_TIMEOUT=10 DOCKER_INSECURE=true DOCKER_TIMEOUT=3 DOCKER_USER=jenkins \\
                            DOCKER_PASSWORD="\$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)" \\
                            JSON_OUTPUT=true REGISTRY_INSECURE=false \\
                            klar "docker-registry.default.svc:5000/${DEV_PROJECT}/tasks:latest" >scan-output; then
                          echo "==== Returned \$? ===="
                        fi
                        if ! test -s scan-output; then
                          echo "==== Failed scanning image ===="
                          rm scan-output
                          exit 1
                        fi
                        echo "==== Done scanning - parsing output ===="
                        for level in Critical Defcon1 High Low Medium Negligible Unknown
                        do
                          echo "==== Listing criticity '\$level' ===="
                          cat scan-output | jq ".Vulnerabilities.\$level"
                        done
                        """
                        def CRITICAL_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.Critical' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        def DEFCON1_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.Defcon1' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        def HIGH_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.High' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        def LOW_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.Low' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        def MEDIUM_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.Medium' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        def NEGLIGIBLE_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.Negligible' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        def UNKNOWN_COUNT = sh (
                            script: "cat scan-output | jq '.Vulnerabilities.Unknown' | sed 's|^null\$|[]|' | jq '.[].Name ' | awk 'END{print NR}'",
                            returnStdout: true
                          ).trim()
                        sh "rm -f scan-output"
                        def score = "UNKNOWN"
                        if (CRITICAL_COUNT != "0" || DEFCON1_COUNT != "0") { score = "CRITICAL" }
                        else {
                          if (HIGH_COUNT != "0") { score = "WARNING" }
                          else { score = "OK" }
                        }
                        def notifyMsg = """
                        [${score}] docker-registry.default.svc:5000/${DEV_PROJECT}/tasks:latest
                        critical: ${CRITICAL_COUNT}
                        defcon1: ${DEFCON1_COUNT}
                        high: ${HIGH_COUNT}
                        low: ${LOW_COUNT}
                        medium: ${MEDIUM_COUNT}
                        negligible: ${NEGLIGIBLE_COUNT}
                        unknown: ${UNKNOWN_COUNT}
                        """.stripIndent()
                        currentBuild.description = notifyMsg
                        echo "${notifyMsg}"
                      } catch(e) {
                        echo "In catch scanning image - ${e}"
                        throw e
                      }
                    }
                  }
                }
              }
              stage('Deploy DEV') {
                steps {
                  script {
                    openshift.withCluster() {
                      openshift.withProject(env.DEV_PROJECT) {
                        openshift.selector("dc", "tasks").rollout().latest();
                      }
                    }
                  }
                }
              }
              stage('Promote to STAGE?') {
                agent {
                  label 'skopeo'
                }
                steps {
                  timeout(time:15, unit:'MINUTES') {
                      input message: "Promote to STAGE?", ok: "Promote"
                  }

                  script {
                    openshift.withCluster() {
                      if (env.ENABLE_QUAY.toBoolean()) {
                        withCredentials([usernamePassword(credentialsId: "${openshift.project()}-quay-cicd-secret", usernameVariable: "QUAY_USER", passwordVariable: "QUAY_PWD")]) {
                          sh "skopeo copy docker://${QUAY_HOSTNAME}/${QUAY_USERNAME}/${QUAY_REPOSITORY}:latest docker://${QUAY_HOSTNAME}/${QUAY_USERNAME}/${QUAY_REPOSITORY}:stage --src-creds \"$QUAY_USER:$QUAY_PWD\" --dest-creds \"$QUAY_USER:$QUAY_PWD\" --src-tls-verify=false --dest-tls-verify=false"
                        }
                      } else {
                        openshift.tag("${env.DEV_PROJECT}/tasks:latest", "${env.STAGE_PROJECT}/tasks:stage")
                      }
                    }
                  }
                }
              }
              stage('Deploy STAGE') {
                steps {
                  script {
                    openshift.withCluster() {
                      openshift.withProject(env.STAGE_PROJECT) {
                        openshift.selector("dc", "tasks").rollout().latest();
                      }
                    }
                  }
                }
              }
            }
          }
      type: JenkinsPipeline
- apiVersion: v1
  kind: ConfigMap
  metadata:
    labels:
      app: cicd-pipeline
      role: jenkins-slave
    name: jenkins-slaves
  data:
    maven-template: |-
      <org.csanchez.jenkins.plugins.kubernetes.PodTemplate>
        <inheritFrom></inheritFrom>
        <name>maven</name>
        <privileged>false</privileged>
        <alwaysPullImage>false</alwaysPullImage>
        <instanceCap>2147483647</instanceCap>
        <idleMinutes>0</idleMinutes>
        <label>maven</label>
        <serviceAccount>jenkins</serviceAccount>
        <nodeSelector></nodeSelector>
        <customWorkspaceVolumeEnabled>false</customWorkspaceVolumeEnabled>
        <workspaceVolume class="org.csanchez.jenkins.plugins.kubernetes.volumes.workspace.EmptyDirWorkspaceVolume">
          <memory>false</memory>
        </workspaceVolume>
        <volumes />
        <containers>
          <org.csanchez.jenkins.plugins.kubernetes.ContainerTemplate>
            <name>jnlp</name>
            <image>openshift/jenkins-agent-maven-35-centos7</image>
            <privileged>false</privileged>
            <alwaysPullImage>false</alwaysPullImage>
            <workingDir>/tmp</workingDir>
            <command></command>
            <args>${computer.jnlpmac} ${computer.name}</args>
            <ttyEnabled>false</ttyEnabled>
            <resourceRequestCpu>200m</resourceRequestCpu>
            <resourceRequestMemory>512Mi</resourceRequestMemory>
            <resourceLimitCpu>1</resourceLimitCpu>
            <resourceLimitMemory>3Gi</resourceLimitMemory>
            <envVars/>
          </org.csanchez.jenkins.plugins.kubernetes.ContainerTemplate>
        </containers>
        <envVars/>
        <annotations/>
        <imagePullSecrets/>
      </org.csanchez.jenkins.plugins.kubernetes.PodTemplate>
    skopeo-template: |-
      <org.csanchez.jenkins.plugins.kubernetes.PodTemplate>
        <inheritFrom></inheritFrom>
        <name>skopeo</name>
        <privileged>false</privileged>
        <alwaysPullImage>false</alwaysPullImage>
        <instanceCap>2147483647</instanceCap>
        <idleMinutes>0</idleMinutes>
        <label>skopeo</label>
        <serviceAccount>jenkins</serviceAccount>
        <nodeSelector></nodeSelector>
        <customWorkspaceVolumeEnabled>false</customWorkspaceVolumeEnabled>
        <workspaceVolume class="org.csanchez.jenkins.plugins.kubernetes.volumes.workspace.EmptyDirWorkspaceVolume">
          <memory>false</memory>
        </workspaceVolume>
        <volumes />
        <containers>
          <org.csanchez.jenkins.plugins.kubernetes.ContainerTemplate>
            <name>jnlp</name>
            <image>docker.io/siamaksade/jenkins-slave-skopeo-centos7</image>
            <privileged>false</privileged>
            <alwaysPullImage>false</alwaysPullImage>
            <workingDir>/tmp</workingDir>
            <command></command>
            <args>${computer.jnlpmac} ${computer.name}</args>
            <ttyEnabled>false</ttyEnabled>
            <resourceRequestCpu>100m</resourceRequestCpu>
            <resourceRequestMemory>512Mi</resourceRequestMemory>
            <resourceLimitCpu>300m</resourceLimitCpu>
            <resourceLimitMemory>1Gi</resourceLimitMemory>
            <envVars/>
          </org.csanchez.jenkins.plugins.kubernetes.ContainerTemplate>
        </containers>
        <envVars/>
        <annotations/>
        <imagePullSecrets/>
      </org.csanchez.jenkins.plugins.kubernetes.PodTemplate>
# Setup Demo
- apiVersion: batch/v1
  kind: Job
  metadata:
    name: cicd-demo-installer
  spec:
    activeDeadlineSeconds: 400
    completions: 1
    parallelism: 1
    template:
      spec:
        containers:
        - env:
          - name: CICD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: HTTP_PROXY
            value: http://${PROXY_HOST}:${PROXY_PORT}/
          - name: HTTPS_PROXY
            value: http://${PROXY_HOST}:${PROXY_PORT}/
          - name: NO_PROXY
            value: ${PROXY_EXCLUDE_NAMES}
          - name: http_proxy
            value: http://${PROXY_HOST}:${PROXY_PORT}/
          - name: https_proxy
            value: http://${PROXY_HOST}:${PROXY_PORT}/
          - name: no_proxy
            value: ${PROXY_EXCLUDE_NAMES}
          command:
          - /bin/bash
          - -x
          - -c
          - |
            if test -z "${PROXY_HOST}"; then
                unset HTTP_PROXY HTTPS_PROXY NO_POXY http_proxy https_proxy no_poxy
            fi

            # setup dev env
            oc import-image wildfly --from=openshift/wildfly-120-centos7 --confirm -n ${DEV_PROJECT}

            if test "${ENABLE_QUAY}" = true; then
              # cicd
              if ! oc describe secret quay-cicd-secret >/dev/null 2>&1; then
                oc create secret generic quay-cicd-secret --from-literal="username=${QUAY_USERNAME}" --from-literal="password=${QUAY_PASSWORD}" -n ${CICD_NAMESPACE}
              fi
              oc label secret quay-cicd-secret credential.sync.jenkins.openshift.io=true -n ${CICD_NAMESPACE} --overwrite=true

              # dev
              if ! oc describe secret quay-cicd-secret -n ${DEV_PROJECT} >/dev/null 2>&1; then
                oc create secret docker-registry quay-cicd-secret --docker-server=${QUAY_HOSTNAME} --docker-username="${QUAY_USERNAME}" --docker-password="${QUAY_PASSWORD}" --docker-email=cicd@redhat.com -n ${DEV_PROJECT}
              fi
              if ! oc describe bc tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
                oc new-build --name=tasks --image-stream=wildfly:latest --binary=true --push-secret=quay-cicd-secret --to-docker --to='${QUAY_HOSTNAME}/${QUAY_USERNAME}/${QUAY_REPOSITORY}:latest' -n ${DEV_PROJECT}
              fi
              if ! oc describe dc tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
                oc new-app --name=tasks --docker-image=${QUAY_HOSTNAME}/${QUAY_USERNAME}/${QUAY_REPOSITORY}:latest --allow-missing-images -n ${DEV_PROJECT}
                oc set triggers dc tasks --remove-all -n ${DEV_PROJECT}
                oc patch dc tasks -p '{"spec": {"template": {"spec": {"containers": [{"name": "tasks", "imagePullPolicy": "Always"}]}}}}' -n ${DEV_PROJECT}
                oc set probe dc/tasks --readiness --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=30 --failure-threshold=10 --period-seconds=10 -n ${DEV_PROJECT}
                oc set probe dc/tasks --liveness  --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=180 --failure-threshold=10 --period-seconds=10 -n ${DEV_PROJECT}
                oc rollout cancel dc/tasks -n ${DEV_PROJECT}
                oc secrets link default quay-cicd-secret --for=pull -n ${DEV_PROJECT}
              fi
              if oc describe is tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
                oc delete is tasks -n ${DEV_PROJECT}
              fi

              # stage
              if ! oc describe secret quay-cicd-secret -n ${STAGE_PROJECT} >/dev/null 2>&1; then
                oc create secret docker-registry quay-cicd-secret --docker-server=${QUAY_HOSTNAME} --docker-username="${QUAY_USERNAME}" --docker-password="${QUAY_PASSWORD}" --docker-email=cicd@redhat.com -n ${STAGE_PROJECT}
              fi
              if ! oc describe bc tasks -n ${STAGE_PROJECT} >/dev/null 2>&1; then
                oc new-app --name=tasks --docker-image=${QUAY_HOSTNAME}/${QUAY_USERNAME}/${QUAY_REPOSITORY}:stage --allow-missing-images -n ${STAGE_PROJECT}
                oc set triggers dc tasks --remove-all -n ${STAGE_PROJECT}
                oc patch dc tasks -p '{"spec": {"template": {"spec": {"containers": [{"name": "tasks", "imagePullPolicy": "Always"}]}}}}' -n ${STAGE_PROJECT}
                oc secrets link default quay-cicd-secret --for=pull -n ${STAGE_PROJECT}
                oc set probe dc/tasks --readiness --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=30 --failure-threshold=10 --period-seconds=10 -n ${STAGE_PROJECT}
                oc set probe dc/tasks --liveness  --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=180 --failure-threshold=10 --period-seconds=10 -n ${STAGE_PROJECT}
                oc rollout cancel dc/tasks -n ${STAGE_PROJECT}
              fi
              if oc describe is tasks -n ${STAGE_PROJECT} >/dev/null 2>&1; then
                oc delete is tasks -n ${STAGE_PROJECT}
              fi
            else
              # dev
              if ! oc describe bc tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
                oc new-build --name=tasks --image-stream=wildfly:latest --binary=true -n ${DEV_PROJECT}
              fi
              if ! oc describe dc tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
                oc new-app tasks:latest --allow-missing-images -n ${DEV_PROJECT}
                oc set triggers dc -l app=tasks --containers=tasks --from-image=tasks:latest --manual -n ${DEV_PROJECT}
                oc set probe dc/tasks --readiness --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=30 --failure-threshold=10 --period-seconds=10 -n ${DEV_PROJECT}
                oc set probe dc/tasks --liveness  --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=180 --failure-threshold=10 --period-seconds=10 -n ${DEV_PROJECT}
                oc rollout cancel dc/tasks -n ${DEV_PROJECT}
              fi

              # stage
              if ! oc describe dc tasks -n ${STAGE_PROJECT} >/dev/null 2>&1; then
                oc new-app tasks:stage --allow-missing-images -n ${STAGE_PROJECT}
                oc set triggers dc -l app=tasks --containers=tasks --from-image=tasks:stage --manual -n ${STAGE_PROJECT}
                oc set probe dc/tasks --readiness --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=30 --failure-threshold=10 --period-seconds=10 -n ${STAGE_PROJECT}
                oc set probe dc/tasks --liveness  --get-url=http://:8080/ws/demo/healthcheck --initial-delay-seconds=180 --failure-threshold=10 --period-seconds=10 -n ${STAGE_PROJECT}
                oc rollout cancel dc/tasks -n ${STAGE_PROJECT}
              fi
            fi

            # dev project
            if ! oc describe svc tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
              oc expose dc/tasks --port=8080 -n ${DEV_PROJECT}
            fi
            if ! oc describe route tasks -n ${DEV_PROJECT} >/dev/null 2>&1; then
              oc expose svc/tasks -n ${DEV_PROJECT}
            fi

            # stage project
            if ! oc describe svc tasks -n ${STAGE_PROJECT} >/dev/null 2>&1; then
              oc expose dc/tasks --port=8080 -n ${STAGE_PROJECT}
            fi
            if ! oc describe route tasks -n ${STAGE_PROJECT} >/dev/null 2>&1; then
              oc expose svc/tasks -n ${STAGE_PROJECT}
            fi

            # deploy gogs
            HOSTNAME=$(oc get route jenkins -o template --template='{{.spec.host}}' | sed "s/jenkins-${CICD_NAMESPACE}.//g")
            GOGS_HOSTNAME="gogs-$CICD_NAMESPACE.$HOSTNAME"

            if test "${PROXY_HOST}"; then
              PROXY=${PROXY_HOST}
              if test "${PROXY_PORT}"; then
                PROXY_PORT=${PROXY_PORT}
              else
                PROXY_PORT=3128
              fi
              if test "$NO_PROXY"; then
                NO_PROXY="$NO_PROXY,*.${HOSTNAME}"
              else
                NO_PROXY="*.${HOSTNAME}"
              fi
              PROXY_URL="http://$PROXY:$PROXY_PORT"
            else
              PROXY=""
              PROXY_PORT=""
              NO_PROXY=""
              PROXY_URL=""
            fi
            if test "${EPHEMERAL}" = true; then
              oc process -f https://raw.githubusercontent.com/faust64/gogs-openshift-docker/master/openshift/gogs-template.yaml \
                  --param=GOGS_VERSION=0.11.34 --param=HOSTNAME=$GOGS_HOSTNAME --param=SKIP_TLS_VERIFY=true "--param=PROXY_HOST=$PROXY" \
                  "--param=PROXY_PORT=$PROXY_PORT" "--param=NO_PROXY=$NO_PROXY" | oc create -f-
            else
              oc process -f https://raw.githubusercontent.com/faust64/gogs-openshift-docker/master/openshift/gogs-persistent-template.yaml \
                  --param=GOGS_VERSION=0.11.34 --param=HOSTNAME=$GOGS_HOSTNAME --param=SKIP_TLS_VERIFY=true "--param=PROXY_HOST=$PROXY" \
                  "--param=PROXY_PORT=$PROXY_PORT" "--param=NO_PROXY=$NO_PROXY" | oc create -f-
            fi

            sleep 5

            if test "${EPHEMERAL}" = true; then
              oc process -f https://raw.githubusercontent.com/faust64/sonarqube/master/sonarqube-template.yml \
                "--param=PROXY_HOST=$PROXY" "--param=PROXY_PORT=$POXY_PORT" "--param=PROXY_EXCLUDE=$NO_PROXY" | oc create -f-
            else
              oc process -f https://raw.githubusercontent.com/faust64/sonarqube/master/sonarqube-persistent-template.yml \
                "--param=PROXY_HOST=$PROXY" "--param=PROXY_PORT=$POXY_PORT" "--param=PROXY_EXCLUDE=$NO_PROXY" \
                "--param=POSTGRES_PERSISTENT_VOLUME_CLAIM_SIZE=${SONARQUBE_DB_VOLUME_CAPACITY}" \
                "--param=SONARQUBE_PERSISTENT_VOLUME_SIZE=${SONARQUBE_APP_VOLUME_CAPACITY}" | oc create -f-
            fi

            if test "${DEPLOY_CHE}" = true; then
              oc process -f https://raw.githubusercontent.com/minishift/minishift/master/addons/che/templates/che-workspace-service-account.yaml \
                  --param SERVICE_ACCOUNT_NAMESPACE=$CICD_NAMESPACE --param=SERVICE_ACCOUNT_NAME=che-workspace | oc create -f-

              oc process -f https://raw.githubusercontent.com/minishift/minishift/master/addons/che/templates/che-server-template.yaml \
                --param ROUTING_SUFFIX=$HOSTNAME --param CHE_MULTIUSER=false \
                --param CHE_VERSION="6.19.0" --param CHE_INFRA_OPENSHIFT_PROJECT=$CICD_NAMESPACE \
                --param CHE_INFRA_KUBERNETES_SERVICE__ACCOUNT__NAME=che-workspace | oc create -f -

              oc set resources deployment/che --limits=cpu=800m,memory=2Gi --requests=cpu=200m,memory=512Mi
              oc patch route che --patch '{"spec":{"tls":{"insecureEdgeTerminationPolicy":"Redirect","termination":"edge"}}}'
            fi

            if test "${DEPLOY_CLAIR}" = true; then
              oc process -f https://raw.githubusercontent.com/faust64/docker-jenkins-agent-klar/master/openshift.yaml \
                "--param=HTTP_PROXY=$PROXY_URL" "--param=HTTPS_PROXY=$PROXY_URL" "--param=NO_PROXY=$NO_PROXY" | oc create -f-
              if test "${EPHEMERAL}" = true; then
                oc process -f https://raw.githubusercontent.com/faust64/openshift-coreos-clair/master/clair-ephemeral.yaml \
                  "--param=HTTP_PROXY=$PROXY_URL" "--param=NO_PROXY=$NO_PROXY" | oc create -f-
              else
                oc process -f https://raw.githubusercontent.com/faust64/openshift-coreos-clair/master/clair-persistent.yaml \
                  "--param=HTTP_PROXY=$PROXY_URL" "--param=NO_PROXY=$NO_PROXY" \
                  "--param=CLAIR_POSTGRES_VOLUME_CAPACITY=${CLAIR_DB_VOLUME_CAPACITY}" | oc create -f-
              fi
            fi

            if test "${EPHEMERAL}" = true; then
              oc process -f https://raw.githubusercontent.com/faust64/nexus/master/nexus3-template.yaml \
                --param=NEXUS_VERSION=3.13.0 --param=MAX_MEMORY=4Gi "--param=HTTP_PROXY=$PROXY_URL" \
                "--param=HTTPS_PROXY=$PROXY_URL" "--param=NO_PROXY=$NO_PROXY" | oc create -f-
            else
              oc process -f https://raw.githubusercontent.com/faust64/nexus/master/nexus3-persistent-template.yaml \
                --param=NEXUS_VERSION=3.13.0 --param=MAX_MEMORY=4Gi "--param=HTTP_PROXY=$PROXY_URL" \
                "--param=VOLUME_CAPACITY=${NEXUS_VOLUME_CAPACITY}" \
                "--param=HTTPS_PROXY=$PROXY_URL" "--param=NO_PROXY=$NO_PROXY" | oc create -f-
            fi

            GOGS_SVC=$(oc get svc gogs -o template --template='{{.spec.clusterIP}}')
            GOGS_USER=gogs
            GOGS_PWD=gogs
            export NO_PROXY=$NO_PROXY,$GOGS_SVC
            export no_proxy=$NO_PROXY

            oc rollout status dc gogs

            while ! curl http://$GOGS_SVC:3000/user/sign_up >/dev/null 2>&1
            do
              echo waiting for gogs to start
              sleep 5
            done

            for retry in one too tri
            do
              _RETURN=$(curl -o /tmp/curl.log -sL --post302 -w "%{http_code}" http://$GOGS_SVC:3000/user/sign_up \
                --form user_name=$GOGS_USER --form password=$GOGS_PWD \
                --form retype=$GOGS_PWD --form email=admin@gogs.com)

              if test $_RETURN = "200" -o $_RETURN = "302"; then
                break
              elif ! test "$retry" = tri; then
                sleep 5
              fi
            done

            if test $_RETURN != "200" -a $_RETURN != "302"; then
              echo "ERROR: Failed to create Gogs admin"
              cat /tmp/curl.log
              exit 255
            fi

            sleep 10

            cat <<EOF >/tmp/data.json
            {
              "clone_addr": "https://github.com/faust64/openshift-tasks.git",
              "uid": 1,
              "repo_name": "openshift-tasks"
            }
            EOF

            _RETURN=$(curl -o /tmp/curl.log -sL -w "%{http_code}" -H "Content-Type: application/json" \
              -u $GOGS_USER:$GOGS_PWD -X POST http://$GOGS_SVC:3000/api/v1/repos/migrate -d @/tmp/data.json)

            if test $_RETURN != "201"; then
              echo "ERROR: Failed to import openshift-tasks GitHub repo"
              cat /tmp/curl.log
              exit 255
            fi

            sleep 5

            cat <<EOF >/tmp/data.json
            {
              "type": "gogs",
              "config": {
                "url": "https://openshift.default.svc.cluster.local/oapi/v1/namespaces/$CICD_NAMESPACE/buildconfigs/tasks-pipeline/webhooks/${WEBHOOK_SECRET}/generic",
                "content_type": "json"
              },
              "events": [
                "push"
              ],
              "active": true
            }
            EOF

            _RETURN=$(curl -o /tmp/curl.log -sL -w "%{http_code}" -H "Content-Type: application/json" \
              -u $GOGS_USER:$GOGS_PWD -X POST http://$GOGS_SVC:3000/api/v1/repos/gogs/openshift-tasks/hooks -d @/tmp/data.json)

            if test $_RETURN != "201"; then
              echo "ERROR: Failed to set webhook"
              cat /tmp/curl.log
              exit 255
            fi
          image: openshift/origin:${OPENSHIFT_IMAGE_TAG}
          name: cicd-demo-installer-job
        restartPolicy: Never
parameters:
- displayName: Clair Database Persistent Volume Size
  name: CLAIR_DB_VOLUME_CAPACITY
  required: true
  value: 10Gi
- displayName: DEV project name
  name: DEV_PROJECT
  required: true
  value: dev
- description: Deploy CoreOS Clair scanning Docker images as part of CI pipelines
  displayName: Deploy CoreOS Clair
  name: DEPLOY_CLAIR
  required: true
  value: "true"
- description: Deploy Eclipse Che in order to use as an online IDE for changing code in this demo
  displayName: Deploy Eclipse Che
  name: DEPLOY_CHE
  required: true
  value: "false"
- description: Integrate image build and deployment with Quay.io
  displayName: Integrate Quay.io
  name: ENABLE_QUAY
  required: true
  value: "false"
- description: Use no persistent storage for Gogs, Nexus, SonarQube and CoreOS Clair (demo)
  displayName: Ephemeral
  name: EPHEMERAL
  required: true
  value: "false"
- displayName: Jenkins Image Source
  name: JENKINS_IMAGE_SOURCE
  required: true
  value: docker.io/openshift/jenkins-2-centos7
- displayName: Jenkins Image Tag
  name: JENKINS_IMAGE_TAG
  required: true
  value: v3.11
- description: List of Jenkins Plugins to load during startup
  displayName: Jenkins Plugins List
  name: JENKINS_PLUGINS
  required: true
  value: sonar,gitlab-hook,generic-webhook-trigger,gogs-webhook,pipeline-npm,gitlab,nexus-artifact-uploader,kubernetes-credentials-provider,http_request,accelerated-build-now-plugin,active-directory,analysis-core,ant,antisamy-markup-formatter,artifactdeployer,build-failure-analyzer,build-name-setter,conditional-buildstep,configurationslicing,custom-tools-plugin,cvs,description-setter,disk-usage,docker-plugin,docker-slaves,durable-task,elastic-axis,email-ext,envinject,external-monitor-job,gerrit-trigger,git-parameter,groovy-label-assignment,PrioritySorter,postbuild-task,jobConfigHistory,leastload,mapdb-api,monitoring,mask-passwords,periodic-reincarnation,plot,preSCMbuildstep,project-stats-plugin,purge-build-queue-plugin,release,repo,slave-setup,slave-status,ssh-agent,throttle-concurrents,timestamper,translation,warnings
- displayName: Jenkins Persistent Volume Size
  name: JENKINS_VOLUME_CAPACITY
  required: true
  value: 10Gi
- displayName: Nexus Persistent Volume Size
  name: NEXUS_VOLUME_CAPACITY
  required: true
  value: 10Gi
- displayName: OpenShift Image Tag
  name: OPENSHIFT_IMAGE_TAG
  required: true
  value: v3.11
- description: HTTP Proxy Host Address
  displayName: HTTP Proxy Host
  name: PROXY_HOST
- displayName: HTTP Proxy Port
  name: PROXY_PORT
- description: Comma-separated list of addresses or names that should not be accessed using HTTP Proxies
  displayName: HTTP Proxy Exclusions
  name: PROXY_EXCLUDE_NAMES
  value: .cluster.local,.svc
- name: QUAY_HOSTNAME
  value: quay.io
- description: Quay.io password to push the images to tasks-sample-app repository on your Quay.io account
  displayName: Quay.io Password
  name: QUAY_PASSWORD
- description: Quay.io repository for pushing Tasks container images
  displayName: Quay.io Image Repository
  name: QUAY_REPOSITORY
  required: true
  value: tasks-app
- description: Quay.io username to push the images to tasks-sample-app repository on your Quay.io account
  displayName: Quay.io Username
  name: QUAY_USERNAME
- displayName: Sonarqube Application Persistent Volume Size
  name: SONARQUBE_APP_VOLUME_CAPACITY
  required: true
  value: 10Gi
- displayName: Sonarqube Database Persistent Volume Size
  name: SONARQUBE_DB_VOLUME_CAPACITY
  required: true
  value: 10Gi
- displayName: STAGE project name
  name: STAGE_PROJECT
  required: true
  value: stage
- description: Webhook secret
  from: '[a-zA-Z0-9]{8}'
  generate: expression
  name: WEBHOOK_SECRET
  required: true
